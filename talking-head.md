# ğŸ—£ï¸ Talking Head Generation

This page lists the top datasets and models for generating lifelike talking heads using images and audio input.

---

## ğŸ§ª Datasets

- [VoxCeleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html) â€“ Speaker identification videos
- [FaceForensics++](https://github.com/ondyari/FaceForensics) â€“ Deepfake detection and generation
- [TalkingHead-1KH](https://github.com/tcwang0509/TalkingHead-1KH) â€“ Large-scale talking head dataset
- [MEAD](https://github.com/uniBruce/Mead) â€“ Multi-expression audio dataset
- [CelebV-HQ](https://github.com/CelebV-HQ/CelebV-HQ) â€“ High-quality talking head benchmark
- [MultiTalk](https://github.com/postech-ami/MultiTalk) â€“ Multi-view, multi-lingual dataset

---

## ğŸ§  Key Models

### ğŸ“½ï¸ 2024â€“2025
- [LivePortrait](https://github.com/KwaiVGI/LivePortrait) â€“ Real-time animation with stitching and control
- [HunyuanPortrait](https://github.com/kkakkkka/HunyuanPortrait) â€“ Condition-controlled portrait animation
- [EMOPortraits](https://github.com/neeek2303/EMOPortraits) â€“ Emotion-enhanced avatars
- [X-Portrait](https://arxiv.org/abs/2403.15931) â€“ Motion retargeting with hierarchical attention

### ğŸï¸ Earlier Models
- [StyleHEAT](https://github.com/FeiiYin/StyleHEAT) â€“ StyleGAN-based one-shot editable face generation
- [MegaPortraits](https://samsunglabs.github.io/MegaPortraits/) â€“ One-shot megapixel avatars
- [DaGAN](https://github.com/harlanhong/CVPR2022-DaGAN) â€“ Depth-aware generation
- [TS-Net](https://github.com/nihaomiao/WACV23_TSNet) â€“ Identity-preserving talking heads

---

ğŸ’¡ **Tip**: Use recent models like LivePortrait and EMOPortraits for real-time, emotion-aware avatar generation in apps.

